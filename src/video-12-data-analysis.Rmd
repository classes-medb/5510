---
title: "Video 12 - Data analysis"
author: "Steve Simon"
output: 
  powerpoint_presentation:
    reference_doc: ../doc/template.pptx
    slide_level: 3
---

```{r echo=FALSE}
source("prelims.R", echo=FALSE)
```

***
`r read_text("objectives12")`

<div class="notes">

Here are the objectives for this week.

</div>

***
`r read_text("readings12")`

<div class="notes">

This is what you should have read already. If you haven't done the reading yet, pause this video and read this material. You'll get more out of the video if you do so.

</div>

***
### Additional topics

* As another aside, I was involved with a similar study (prospective, not retrospective). We planned this study using a one-sided hypothesis (remote prayer has a positive effect on health). The Institutional Review Board suggested changing this to a two-sided hypothesis (remote prayer has either a positive or a negative effect on health). Thankfully, we did not observe an outcome in the opposite tail as that would have been very difficult to explain.

***
### Making Inferences - NHST 

+ Populations versus Samples
+ Use inferential statistics
	+ Sample statistics (M, SD) <U+F0E8>
	+ Population parameters (mu, sigma)
+ Null Hypothesis Significance Testing (NHST)
	+ Null hypothesis (H 0 )
	+ Alternative hypothesis (H 1 )
		+ AKA research hypothesis
		+ Directional
		+ Non-directional

<div class="notes">

We are talking about data analysis and interpretation. Planning. Some of this will be familiar to you. This is not a full statistical coverage of the topic.

Take the data from the sample and make inferences about the population. The sample is a subset. Inferential statistics is the process by which you infer information about the population.

NHST is the traditional way that a huge amount of research relies on.

Null hypothesis is no difference or no relationship. The alternative is often called the research hypothesis.

</div>

***
### Making Inferences - NHST 

+ NHST – Goal of research –
	+ Reject the H 0 in favor of H 1
+ “Reject” the null hypothesis
	+ Practically – “reject” means difference / relationship greater than just random variability
+ Alternative hypothesis –
	+ 3 versions
		+ Non-directional
		+ Directional positive
		+ Directional negative

<div class="notes">

Does the data allow us to reject the null hypothesis. Rejecting means the difference or relationship is greater than what you'd expect due to sampling error.

[[Directional only for two group comparisons or bivariate relationships]]

never talk about proving the null hypothesis. A large p-value does not mean that you proved the null hypothesis. There might be sources of error that lead to failure to reject the null hypothesis.

</div>

***
### Making Inferences - NHST 

+ Directional vs Non-directional H 1
	+ Comparing treatment to control
	+ Comparing different treatments
+ Choosing directional vs non-directional
	+ Basis for choice
	+ Consequences
		+ Statistical analysis
		+ Interpretation

<div class="notes">

Directional is more likely when comparing a treatment to a control [[placebo]]. When comparing two different treatments, you would have to use a non-directional hypothesis.

Is there existing evidence to support a directional hypothesis.

If you use a directional hypothesis, and you get an extreme result in the opposite direction, you can't claim statistical significance.

Some people think that directional hypotheses are "cheating".

</div>

***
### Making Inferences - NHST 

+ Sampling review
	+ Target / theoretical population
	+ Accessible population
	+ Sample
+ Inference from the study sample to the population

<div class="notes">

So how well does your sample reflect the population?

</div>

***
### Making Inferences - NHST 

![](../images/image-12-01.png)

<div class="notes">

+ Example

Figure 16.1 from your book.

Flow chart of selecting from a population, randomizing to two groups, and then comparing the results in each group, and choosing between two hypotheses.

</div>

***
### Making Inferences - NHST 

+ Accessible population -> Sample
+ Random assignment to groups
+ Conduct study and collect data
+ Conduct statistical analysis
	+ Intervention group: mean = 73
	+ Control group: mean = 65

<div class="notes">

[[This is a re-iteration of Figure 16.1]]

From your basic Statistics class, you may recognize that this setting would require a two-sample t-test.

[[Knowing which statistic to use in what setting is one of the most difficult tasks that you will encounter.]]

</div>

***
### Making Inferences - NHST 

+ Significant difference or not?
	+ Inferential statistics – allow you to determine this
+ Reject the null ->
	+ The observed difference is highly unlikely if the null hypothesis is actually true
+ Fail to reject the null ->
	+ We can not say that the observed difference is highly unlikely
	+ Do NOT “accept” the null hypothesis

<div class="notes">

[[If a particular sample result is unlikely under the null hypothesis, this causes you to question the null hypothesis.]]

Reasons why you failed to reject the null hypothesis. A poorly implemented intervention, failure to use valid and reliabile measures, quality problems during the study.

Why never say that we accept the null.

</div>

***
### Making Inferences - NHST 

+ ( Portney & Watkins, 2009)

<div class="notes">

This is a table of possible outcomes H0 true, H0 false versus reject H0, accept H0.

Define power as the probability of rejecting the null hypotheis when the alternative hypothesis is true. [[Since the ]]

</div>

***
```{r tbl8, echo = FALSE, eval=FALSE}
tbl8 <- tibble::tribble(
~` `, ~`TRUTH`, ~` `,
"DECISION","H o is true (there is no relationship)","H o is false (there is a relationship)",
"Reject H o (you find a relationship)","Type I Error Alpha","Correct  (Decision agrees with Truth ) Power",
"Do not reject H o (you do NOT find a relationship)","Correct  (Decision agrees with Truth)","Type II Error Beta (Power = 1 - Beta)"
)

kableExtra::kable_styling(knitr::kable(tbl8), font_size = 18)
```

<div class="notes">



</div>

***
### Making Inferences - NHST 

![](../images/image-12-02.png)

<div class="notes">

+ Statistical testing – possible outcomes

Figure 16.2 provides a different way of displaying Type I and Type II errors in a two by two table.

</div>

***
### Making Inferences - NHST 

![](../images/image-12-03.png)

<div class="notes">

+ Statistical testing – possible outcomes

Two normal distributions and bell shaped curves. 

Figure 16.3 from your book. Directional negative hypothesis. Example an intervention that results in a reduction in symptoms/pain.

</div>

***
### Making Inferences - NHST 

+ Statistical testing
	+ Fig 16.3 – Directional negative
		+ Example – hypothesize that intervention will result in reduction of symptoms
	+ If you made a directional positive alternative hypothesis …. ?

<div class="notes">

[[This is a rehash of Figure 16.3.]]

</div>

***
### Making Inferences - NHST 

![](../images/image-12-04.png)

<div class="notes">

+ Statistical testing
	+ Fig 16.4 – Non-directional

</div>

***
### Null value

```{r null-value, echo=FALSE}
x <- seq(-3.5, 6.5, length=100)
y <- dnorm(x)
plot(x, y, xlab=" ", ylab=" ", axes=FALSE, type="n", ylim=c(0, 0.6))
abline(h=0)
segments(0, 0, 0, 0.45)
text(0, 0.55, cex=0.5, "Null\nvalue")
```

***
### Critical value

```{r critical-value, echo=FALSE}
x <- seq(-3.5, 6.5, length=100)
y <- dnorm(x)
lb <- c("\nNull\nvalue", "\nCritical\nvalue")
plot(x, y, xlab=" ", ylab=" ", axes=FALSE, type="n", ylim=c(0, 0.6))
abline(h=0)
segments(0, 0, 0, 0.45, col="gray")
text(0, 0.55, cex=0.5, "Null\nvalue", col="gray")
segments(1.2, 0, 1.2, 0.45)
text(1.2, 0.55, cex=0.5, "Critical\nvalue")
```

***
### Alpha level

```{r alpha-level, echo=FALSE}
x <- seq(-3.5, 6.5, length=100)
y <- dnorm(x)
lb <- c("\nNull\nvalue", "\nCritical\nvalue")
plot(x, y, xlab=" ", ylab=" ", axes=FALSE, type="l", ylim=c(0, 0.6))
abline(h=0)
segments(0, 0, 0, 0.45, col="gray")
text(0, 0.55, cex=0.5, "Null\nvalue", col="gray")
segments(1.2, 0, 1.2, 0.45, col="gray")
text(1.2, 0.55, cex=0.5, "Critical\nvalue", col="gray")
```



```{r beta-level, echo=FALSE}
x <- seq(-3.5, 6.5, length=100)
y <- dnorm(x, m=3)
lb <- c("\nNull\nvalue", "\nCritical\nvalue")
plot(x, y, xlab=" ", ylab=" ", axes=FALSE, type="l", ylim=c(0, 0.6))
abline(h=0)
segments(0, 0, 0, 0.45, col="gray")
text(0, 0.55, cex=0.5, "Null\nvalue", col="gray")
segments(1.2, 0, 1.2, 0.45, col="gray")
text(1.2, 0.55, cex=0.5, "Critical\nvalue", col="gray")
```

***
### Power Analysis 

+ Probability of rejecting a false H 0
	+ This is a GOOD thing!
	+ Want to maximize this (within reasonable limits!)
	+ What is power analysis
	+ “… the probability that his investigation would lead to statistically significant results.”

<div class="notes">



</div>

***
### Power Analysis 

+ ( Portney & Watkins, 2009)

<div class="notes">



</div>

***
```{r tbl14, echo = FALSE, eval=FALSE}
tbl14 <- tibble::tribble(
~` `, ~`TRUTH`, ~` `,
"DECISION","H o is true (there is no relationship)","H o is false (there is a relationship)",
"Reject H o (you find a relationship)","Type I Error Alpha","Correct  (Decision agrees with Truth ) Power",
"Do not reject H o (you do NOT find a relationship)","Correct  (Decision agrees with Truth)","Type II Error Beta (Power = 1 - Beta)"
)

kableExtra::kable_styling(knitr::kable(tbl14), font_size = 18)
```

<div class="notes">



</div>

***
### Power Analysis 

![](../images/image-12-05.png)

<div class="notes">

+ Power of a study – probability of rejecting a false null hypothesis

</div>

***
### Power Analysis 

+ Statistical power analysis concepts (Cohen)
	+ Significance criterion – alpha
	+ Power – desired level
	+ Sample size
	+ Effect size
+ Power analysis method depends on research design

<div class="notes">



</div>

***
### Power Analysis 

+ Performing a power analysis when planning a study
	+ What is the study design?
	+ What do you already know about the measure you are interested in?
	+ What significance level to you want to use for hypothesis testing?
	+ What level of power do you want to achieve?

<div class="notes">



</div>

***
### Power Analysis 

![](../images/image-12-06.png)

<div class="notes">

+ Determining power (Fig 16.1)

</div>

***
### Power Analysis 

+ Increasing power –
	+ Alpha level
	+ Formulation of hypothesis
	+ Decrease variability / increase precision
		+ Groups
		+ Outcome measure(s)
	+ Increase sample size

<div class="notes">



</div>

***
### Power Analysis 

![](../images/image-12-07.png)

<div class="notes">



</div>

***
### Power Analysis 

![](../images/image-12-08.png)

<div class="notes">



</div>

***
### Problems with NHST 

+ Knowledge based on outcome of single study
+ Interpretation of statistical significance
+ Complications
	+ H 0 is rarely true – in a strict sense
	+ Too large of a sample size – hard NOT to get statistical significance
	+ Significance testing as a dichotomous decision
	+ Interpretation of changes in the p value
	+ Statistical significant versus clinical/ substative meaningfulness

<div class="notes">

There is always a level of uncertainty associated with a single study.

[[ASA statement on p-values]]

[[Sackett article. http://www.cmaj.ca/content/165/9/1226.short or http://blog.pmean.com/physiological-statistics/ ]]

[[ Example of PiFace http://blog.pmean.com/simple-sample-size/ ]]

[[ Range of clinical indifference http://www.pmean.com/04/confidence.html ]]

[[p-values with lots of zeros, doesn't make up for biases in the study.]]

</div>

***
### Improving NHST 

+ Propose specific alternative hypotheses
+ Use a random sample if possible
+ Use an outcome variable that has good reliability and validity
+ Have a good idea of the level of difference that will be clinically important

<div class="notes">



</div>

***
### Making Inferences - EBA 

+ EBA – Evidence-Based Approach
	+ Reliability of findings
	+ Accumulation of evidence
+ Premise – “… a single study is not sufficient to use as evidence to substantiate a hypothesis or theory.”
+ Methods
	+ Confidence intervals
	+ Effect sizes
	+ Meta-analysis

<div class="notes">



</div>

***
### Making Inferences - EBA 

+ Confidence Intervals (CI)
	+ Range of scores that should contain the true population score
+ CI <U+F0E8> An interval around the point estimate
+ CI <U+F0E8> “… range of the dependent variable scores that *should contain the true population difference between means* .”
+ CI computed using sample mean and standard deviation

<div class="notes">



</div>

***
### Making Inferences - EBA 

+ Interpretation of CI –
	+ 95% CI most common
	+ 95% CI – with infinite studies and computed CI, the true population difference would be found within 95% of the intervals
	+ NOT – .95 probability that true population difference is within the CI computed from our single study
	+ Option – 95% CI for a given study “… *estimates* the population mean difference with 95% confidence.”

<div class="notes">



</div>

***
### Making Inferences - EBA 

+ Why compute and report CI?
	+ Part of philosophy to encourage replication
	+ Size of interval – “… how much of the estimate might be due to sampling error.”

<div class="notes">



</div>

***
### Making Inferences - EBA 

![](../images/image-12-09.png)

<div class="notes">

+ Interpreting 95% CI (Fig 17.1)

</div>

***
### Making Inferences – EBA 

+ Effect size –
	+ Strength of relationship between IV & DV
	+ Magnitude of the difference between levels of the IV with respect to the DV
	+ 3 types of effect size measures
		+ r family
		+ d family
		+ Measures of risk potency

<div class="notes">



</div>

***
### Making Inferences – EBA 

![](../images/image-12-10.png)

<div class="notes">

+ Why is effect size at least as important as significance level?
	+ Influence of sample size on results

</div>

***
### Making Inferences – EBA 

+ Effect sizes –
	+ Unstandardized – in the units of the raw DV
	+ Standardized –
		+ Standardized using pooled standard deviation of the groups
		+ Measure that can be used to compare to other studies with different DVs

<div class="notes">



</div>

***
### Making Inferences – EBA 

+ Types of effect sizes –
	+ R family – strength of association
	+ D family – magnitude of differences
	+ Measures of risk potency – when both IV and DV are dichotomous
		+ Odds ratio
		+ Relative risk
		+ Risk difference

<div class="notes">



</div>

***
### Making Inferences – EBA 

+ R family of effect sizes – association
	+ r 2  vs r
+ Cohen’s guidelines
	+ Weak approx +/- .1
	+ Medium approx +/- .3
	+ Strong approx +/- .5
+ Authors labeling
	+ Less than typical
	+ Typical
	+ Greater than typical
+ Also rho, phi, eta, R

<div class="notes">



</div>

***
### Making Inferences – EBA 

+ D family of effect sizes – differences
+ d <U+F0E8> Two group comparison
	+ Treatment group mean – Comparison group mean
	+ Divided by pooled standard deviations from both samples
+ eta 2  <U+F0E8> Multiple group comparison
	+ Statistics packages will compute
	+ Interpret like r 2 (amount of variance in DV accounted for by IV)

<div class="notes">



</div>

***
### Making Inferences – EBA 

+ Risk family of effect sizes – When both IV and DV are dichotomous
	+ Phi – measure of association / correlation
+ Clinical / medical research – the risk of clinical outcomes
	+ Relative risk – ratio that compares the risk of an outcome between groups
	+ Risk difference – percentage difference that compares risk of an outcome between groups
	+ Odds ratio – Odds of outcome in control group compared to odds in treatment group

<div class="notes">



</div>

***
### Making Inferences – EBA 

![](../images/image-12-11.png)

<div class="notes">

+ Interpretation of effect sizes –

</div>

***
### Making Inferences – EBA 

+ Value of effect sizes –
	+ Indicates the strength of a relationship or a difference
	+ Allows you
		+ Combine results from studies with dissimilar outcome measures
		+ Use findings of previous study to plan study with different outcome measure
+ Online source to perform power analysis –
	+ Sample Power (part of SPSS)
	+ Russell Lenth – U of Iowa

<div class="notes">



</div>

***
### Making Inferences – EBA 

+ Meta-Analysis
	+ Research synthesis of multiple studies
	+ Uses effect size value from each study
	+ Advantage over systematic review – compute a summary statistic that represents overall estimate
	+ Provides evidence of reliability of research finding
	+ Include findings from studies that failed to find statistical significance
	+ Increased external validity

<div class="notes">



</div>

***
### Making Inferences – EBA 

![](../images/image-12-12.png)

<div class="notes">

+ Simoni et al., 2006

</div>

***
### Making Inferences – EBA 

![](../images/image-12-13.png)

<div class="notes">

+ Simoni et al., 2006

</div>

***
### Assignment #9 

+ Complete an “outline ” of your written proposal. Refer to the “Research Proposal Structure Overview/Structure” document in the Course Content folder on Blackboard. This “outline” should reflect a substantial amount of detail including sub-headings in the literature review section and methods section. Sections that reflect earlier assignments should contain near-complete drafts of the information that is relevant to your proposed project.
+ Available resource –
	+ Research Proposal Structure Information document
		+ Week by Week / General Information

<div class="notes">



</div>

***
`r read_text("hw12", fri[12])`

<div class="notes">



</div>

***
`r read_text("discussion12", fri[12])`

<div class="notes">



</div>

***

### Additional slides